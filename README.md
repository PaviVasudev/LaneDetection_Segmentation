# Lane Detection in self-driving cars
Segmentation is performed on road images using a U-net model to extract road lanes (can be used by self driven cars)

The aim of this project is to design and train a model capable of segmenting the boundaries of a lane given an image of a road and differentiating the left and right boundaries of the lane. In order to implement the project, the UNet architecture was employed. The UNet architecture is a “FCNN” ie, a fully convolutional neural network. UNet, evolved from the traditional convolutional neural network, was first designed and applied in 2015 to process biomedical images. As a traditional convolution network that focuses on classification, UNet was developed for the purposes of segmentation. The model was built using TensorFlow and was compiled with an ‘Adam’ optimizer function along with ‘categorical cross entropy’ loss function. Training images along with their corresponding mask were fed into the network for training. The dataset taken from Kaggle (https://www.kaggle.com/thomasfermi/lane-detection-for-carla-driving-simulator) consists of 3074 training images of dimension 1024 x 512 x 3 along with the corresponding mask. The masks were originally in RGB, but were converted to B/W to conserve RAM and computational time. The model was trained for 5 epochs, and all images were scored on 'general accuracy, recall, precision, and intersection over union (IOU).' The architecture produced a training IOU of 0.799 and a validation IOU of 0.781, a training accuracy of 98.6 percent and a validation accuracy of 98.5 percent, as well as an output that segments the lane in the provided image as closely as feasible to the ground truth.
